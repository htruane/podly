"""initial schema

Revision ID: 5cfd4fc88067
Revises:
Create Date: 2025-11-06 16:40:33.672720

"""

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = "5cfd4fc88067"
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "app_settings",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("background_update_interval_minute", sa.Integer(), nullable=True),
        sa.Column("automatically_whitelist_new_episodes", sa.Boolean(), nullable=False),
        sa.Column("post_cleanup_retention_days", sa.Integer(), nullable=True),
        sa.Column(
            "number_of_episodes_to_whitelist_from_archive_of_new_feed",
            sa.Integer(),
            nullable=False,
        ),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "feed",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("alt_id", sa.Text(), nullable=True),
        sa.Column("title", sa.Text(), nullable=False),
        sa.Column("description", sa.Text(), nullable=True),
        sa.Column("author", sa.Text(), nullable=True),
        sa.Column("rss_url", sa.Text(), nullable=False),
        sa.Column("image_url", sa.Text(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("rss_url"),
    )
    op.create_table(
        "jobs_manager_run",
        sa.Column("id", sa.String(length=36), nullable=False),
        sa.Column("status", sa.String(length=50), nullable=False),
        sa.Column("trigger", sa.String(length=100), nullable=False),
        sa.Column("started_at", sa.DateTime(), nullable=True),
        sa.Column("completed_at", sa.DateTime(), nullable=True),
        sa.Column("total_jobs", sa.Integer(), nullable=False),
        sa.Column("queued_jobs", sa.Integer(), nullable=False),
        sa.Column("running_jobs", sa.Integer(), nullable=False),
        sa.Column("completed_jobs", sa.Integer(), nullable=False),
        sa.Column("failed_jobs", sa.Integer(), nullable=False),
        sa.Column("skipped_jobs", sa.Integer(), nullable=False),
        sa.Column("context_json", sa.JSON(), nullable=True),
        sa.Column("counters_reset_at", sa.DateTime(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=True),
        sa.Column("updated_at", sa.DateTime(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("jobs_manager_run", schema=None) as batch_op:
        batch_op.create_index(
            batch_op.f("ix_jobs_manager_run_status"), ["status"], unique=False
        )

    op.create_table(
        "llm_settings",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("llm_api_key", sa.Text(), nullable=True),
        sa.Column("llm_model", sa.Text(), nullable=False),
        sa.Column("openai_base_url", sa.Text(), nullable=True),
        sa.Column("openai_timeout", sa.Integer(), nullable=False),
        sa.Column("openai_max_tokens", sa.Integer(), nullable=False),
        sa.Column("llm_max_concurrent_calls", sa.Integer(), nullable=False),
        sa.Column("llm_max_retry_attempts", sa.Integer(), nullable=False),
        sa.Column("llm_max_input_tokens_per_call", sa.Integer(), nullable=True),
        sa.Column("llm_enable_token_rate_limiting", sa.Boolean(), nullable=False),
        sa.Column("llm_max_input_tokens_per_minute", sa.Integer(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "output_settings",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("fade_ms", sa.Integer(), nullable=False),
        sa.Column("min_ad_segement_separation_seconds", sa.Integer(), nullable=False),
        sa.Column("min_ad_segment_length_seconds", sa.Integer(), nullable=False),
        sa.Column("min_confidence", sa.Float(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "processing_settings",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("system_prompt_path", sa.Text(), nullable=False),
        sa.Column("user_prompt_template_path", sa.Text(), nullable=False),
        sa.Column("num_segments_to_input_to_prompt", sa.Integer(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "users",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("username", sa.String(length=255), nullable=False),
        sa.Column("password_hash", sa.String(length=255), nullable=False),
        sa.Column("role", sa.String(length=50), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("users", schema=None) as batch_op:
        batch_op.create_index(
            batch_op.f("ix_users_username"), ["username"], unique=True
        )

    op.create_table(
        "whisper_settings",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("whisper_type", sa.Text(), nullable=False),
        sa.Column("local_model", sa.Text(), nullable=False),
        sa.Column("remote_model", sa.Text(), nullable=False),
        sa.Column("remote_api_key", sa.Text(), nullable=True),
        sa.Column("remote_base_url", sa.Text(), nullable=False),
        sa.Column("remote_language", sa.Text(), nullable=False),
        sa.Column("remote_timeout_sec", sa.Integer(), nullable=False),
        sa.Column("remote_chunksize_mb", sa.Integer(), nullable=False),
        sa.Column("groq_api_key", sa.Text(), nullable=True),
        sa.Column("groq_model", sa.Text(), nullable=False),
        sa.Column("groq_language", sa.Text(), nullable=False),
        sa.Column("groq_max_retries", sa.Integer(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "feed_access_token",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("token_id", sa.String(length=32), nullable=False),
        sa.Column("token_hash", sa.String(length=64), nullable=False),
        sa.Column("feed_id", sa.Integer(), nullable=False),
        sa.Column("user_id", sa.Integer(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("last_used_at", sa.DateTime(), nullable=True),
        sa.Column("revoked", sa.Boolean(), nullable=False),
        sa.ForeignKeyConstraint(
            ["feed_id"],
            ["feed.id"],
        ),
        sa.ForeignKeyConstraint(
            ["user_id"],
            ["users.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("feed_access_token", schema=None) as batch_op:
        batch_op.create_index(
            batch_op.f("ix_feed_access_token_token_id"), ["token_id"], unique=True
        )

    op.create_table(
        "post",
        sa.Column("feed_id", sa.Integer(), nullable=False),
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("guid", sa.Text(), nullable=False),
        sa.Column("download_url", sa.Text(), nullable=False),
        sa.Column("title", sa.Text(), nullable=False),
        sa.Column("unprocessed_audio_path", sa.Text(), nullable=True),
        sa.Column("processed_audio_path", sa.Text(), nullable=True),
        sa.Column("description", sa.Text(), nullable=True),
        sa.Column("release_date", sa.DateTime(timezone=True), nullable=True),
        sa.Column("duration", sa.Integer(), nullable=True),
        sa.Column("whitelisted", sa.Boolean(), nullable=False),
        sa.Column("image_url", sa.Text(), nullable=True),
        sa.Column("download_count", sa.Integer(), nullable=True),
        sa.ForeignKeyConstraint(
            ["feed_id"],
            ["feed.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("download_url"),
        sa.UniqueConstraint("guid"),
    )
    op.create_table(
        "processing_job",
        sa.Column("id", sa.String(length=36), nullable=False),
        sa.Column("jobs_manager_run_id", sa.String(length=36), nullable=True),
        sa.Column("post_guid", sa.String(length=255), nullable=False),
        sa.Column("status", sa.String(length=50), nullable=False),
        sa.Column("current_step", sa.Integer(), nullable=True),
        sa.Column("step_name", sa.String(length=100), nullable=True),
        sa.Column("total_steps", sa.Integer(), nullable=True),
        sa.Column("progress_percentage", sa.Float(), nullable=True),
        sa.Column("started_at", sa.DateTime(), nullable=True),
        sa.Column("completed_at", sa.DateTime(), nullable=True),
        sa.Column("error_message", sa.Text(), nullable=True),
        sa.Column("scheduler_job_id", sa.String(length=255), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=True),
        sa.Column("segments_approved", sa.Boolean(), nullable=False),
        sa.ForeignKeyConstraint(
            ["jobs_manager_run_id"],
            ["jobs_manager_run.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("processing_job", schema=None) as batch_op:
        batch_op.create_index(
            batch_op.f("ix_processing_job_created_at"), ["created_at"], unique=False
        )
        batch_op.create_index(
            batch_op.f("ix_processing_job_jobs_manager_run_id"),
            ["jobs_manager_run_id"],
            unique=False,
        )
        batch_op.create_index(
            batch_op.f("ix_processing_job_post_guid"), ["post_guid"], unique=False
        )

    op.create_table(
        "model_call",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("post_id", sa.Integer(), nullable=False),
        sa.Column("first_segment_sequence_num", sa.Integer(), nullable=False),
        sa.Column("last_segment_sequence_num", sa.Integer(), nullable=False),
        sa.Column("model_name", sa.String(), nullable=False),
        sa.Column("prompt", sa.Text(), nullable=False),
        sa.Column("response", sa.Text(), nullable=True),
        sa.Column("timestamp", sa.DateTime(), nullable=False),
        sa.Column("status", sa.String(), nullable=False),
        sa.Column("error_message", sa.Text(), nullable=True),
        sa.Column("retry_attempts", sa.Integer(), nullable=False),
        sa.ForeignKeyConstraint(
            ["post_id"],
            ["post.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("model_call", schema=None) as batch_op:
        batch_op.create_index(
            "ix_model_call_post_chunk_model",
            [
                "post_id",
                "first_segment_sequence_num",
                "last_segment_sequence_num",
                "model_name",
            ],
            unique=True,
        )

    op.create_table(
        "segment_override",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("post_id", sa.Integer(), nullable=False),
        sa.Column("start_time", sa.Float(), nullable=False),
        sa.Column("end_time", sa.Float(), nullable=False),
        sa.Column("user_approved", sa.Boolean(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(
            ["post_id"],
            ["post.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "transcript_segment",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("post_id", sa.Integer(), nullable=False),
        sa.Column("sequence_num", sa.Integer(), nullable=False),
        sa.Column("start_time", sa.Float(), nullable=False),
        sa.Column("end_time", sa.Float(), nullable=False),
        sa.Column("text", sa.Text(), nullable=False),
        sa.ForeignKeyConstraint(
            ["post_id"],
            ["post.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("transcript_segment", schema=None) as batch_op:
        batch_op.create_index(
            "ix_transcript_segment_post_id_sequence_num",
            ["post_id", "sequence_num"],
            unique=True,
        )

    op.create_table(
        "identification",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("transcript_segment_id", sa.Integer(), nullable=False),
        sa.Column("model_call_id", sa.Integer(), nullable=False),
        sa.Column("confidence", sa.Float(), nullable=True),
        sa.Column("label", sa.String(), nullable=False),
        sa.ForeignKeyConstraint(
            ["model_call_id"],
            ["model_call.id"],
        ),
        sa.ForeignKeyConstraint(
            ["transcript_segment_id"],
            ["transcript_segment.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("identification", schema=None) as batch_op:
        batch_op.create_index(
            "ix_identification_segment_call_label",
            ["transcript_segment_id", "model_call_id", "label"],
            unique=True,
        )

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("identification", schema=None) as batch_op:
        batch_op.drop_index("ix_identification_segment_call_label")

    op.drop_table("identification")
    with op.batch_alter_table("transcript_segment", schema=None) as batch_op:
        batch_op.drop_index("ix_transcript_segment_post_id_sequence_num")

    op.drop_table("transcript_segment")
    op.drop_table("segment_override")
    with op.batch_alter_table("model_call", schema=None) as batch_op:
        batch_op.drop_index("ix_model_call_post_chunk_model")

    op.drop_table("model_call")
    with op.batch_alter_table("processing_job", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_processing_job_post_guid"))
        batch_op.drop_index(batch_op.f("ix_processing_job_jobs_manager_run_id"))
        batch_op.drop_index(batch_op.f("ix_processing_job_created_at"))

    op.drop_table("processing_job")
    op.drop_table("post")
    with op.batch_alter_table("feed_access_token", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_feed_access_token_token_id"))

    op.drop_table("feed_access_token")
    op.drop_table("whisper_settings")
    with op.batch_alter_table("users", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_users_username"))

    op.drop_table("users")
    op.drop_table("processing_settings")
    op.drop_table("output_settings")
    op.drop_table("llm_settings")
    with op.batch_alter_table("jobs_manager_run", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_jobs_manager_run_status"))

    op.drop_table("jobs_manager_run")
    op.drop_table("feed")
    op.drop_table("app_settings")
    # ### end Alembic commands ###
